{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa15d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4977, 17)\n",
      "X_test shape: (1245, 17)\n",
      "Crop Classes: ['Barley' 'Buckwheat' 'Cabbage' 'Cauliflower' 'Ginger' 'Large Cardamom'\n",
      " 'Maize' 'Mandarin' 'Mustard' 'Orange' 'Paddy (Rice)' 'Peas' 'Potato'\n",
      " 'Soybean' 'Sugarcane' 'Tomato' 'Turmeric' 'Wheat']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load dataset\n",
    "data = pd.read_csv(r\"C:\\Ignite36\\Final_Merged_Dataset.csv\")\n",
    "\n",
    "# 2. Extract month from Date\n",
    "data[\"Month\"] = pd.to_datetime(data[\"Date\"], errors=\"coerce\").dt.month\n",
    "\n",
    "# 3. Features (X) and Target (y)\n",
    "X = data.drop([\"crop name\"], axis=1)   # input features\n",
    "y = data[\"crop name\"]                  # target variable\n",
    "\n",
    "# 4. Drop non-useful columns\n",
    "X = X.drop([\"Date\", \"Radiation_Sanity\"], axis=1, errors='ignore')\n",
    "\n",
    "# 5. Define categorical and numerical columns\n",
    "categorical_cols = [\"Season\", \"growth stage\"]   # categorical features\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# 6. Preprocessing: OneHot for categorical, Scaling for numerical\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", StandardScaler(), numeric_cols)\n",
    "    ])\n",
    "\n",
    "X_processed = ct.fit_transform(X)\n",
    "\n",
    "# 7. Encode target (crop name → numbers)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# 8. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Crop Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1457ebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Temperature_C', 'Relative_Humidity_%', 'Pressure_Pa',\n",
       "       'Net_Radiation_MJ_m2_day', 'Wind_Speed_m_s', 'Temperature_F',\n",
       "       'Radiation_Sanity', 'ET0', 'ETc', 'Season', 'crop name', 'growth stage',\n",
       "       'Kc', 'Month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b88b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_categorical shape: (4977, 18)\n",
      "y_test_categorical shape: (1245, 18)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(le.classes_)  # total number of crops\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(\"y_train_categorical shape:\", y_train_categorical.shape)\n",
    "print(\"y_test_categorical shape:\", y_test_categorical.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817cd3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4977, 17), (4977, 18), (1245, 17), (1245, 18))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train_categorical.shape, X_test.shape, y_test_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fee1b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m4,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m2,322\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,826</span> (155.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,826\u001b[0m (155.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,826</span> (155.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,826\u001b[0m (155.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Input & output sizes\n",
    "input_dim = X_train.shape[1]        # number of features after preprocessing\n",
    "num_classes = len(le.classes_)      # number of crops\n",
    "\n",
    "# Building model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),   # First hidden layer\n",
    "    Dropout(0.3),                                              # Dropout to prevent overfitting\n",
    "    Dense(128, activation='relu'),                              # Second hidden layer\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')                   # Output layer\n",
    "])\n",
    "\n",
    "# Compiling model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723fe04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2783 - loss: 1.9363 - val_accuracy: 0.3968 - val_loss: 1.4406\n",
      "Epoch 2/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4067 - loss: 1.4003 - val_accuracy: 0.5285 - val_loss: 1.1591\n",
      "Epoch 3/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 1.1433 - val_accuracy: 0.5687 - val_loss: 0.9431\n",
      "Epoch 4/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.9610 - val_accuracy: 0.6137 - val_loss: 0.8018\n",
      "Epoch 5/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6192 - loss: 0.8315 - val_accuracy: 0.7133 - val_loss: 0.7025\n",
      "Epoch 6/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6669 - loss: 0.7341 - val_accuracy: 0.7390 - val_loss: 0.5967\n",
      "Epoch 7/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.6612 - val_accuracy: 0.7518 - val_loss: 0.5435\n",
      "Epoch 8/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.6055 - val_accuracy: 0.7912 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7480 - loss: 0.5422 - val_accuracy: 0.7719 - val_loss: 0.4427\n",
      "Epoch 10/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.4996 - val_accuracy: 0.8024 - val_loss: 0.4038\n",
      "Epoch 11/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4793 - val_accuracy: 0.7928 - val_loss: 0.3862\n",
      "Epoch 12/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.4479 - val_accuracy: 0.8080 - val_loss: 0.3711\n",
      "Epoch 13/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.4149 - val_accuracy: 0.7968 - val_loss: 0.3485\n",
      "Epoch 14/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.4012 - val_accuracy: 0.8064 - val_loss: 0.3357\n",
      "Epoch 15/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.3849 - val_accuracy: 0.8064 - val_loss: 0.3294\n",
      "Epoch 16/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.3755 - val_accuracy: 0.8161 - val_loss: 0.3174\n",
      "Epoch 17/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.3613 - val_accuracy: 0.8145 - val_loss: 0.3177\n",
      "Epoch 18/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.3570 - val_accuracy: 0.8257 - val_loss: 0.3040\n",
      "Epoch 19/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.3511 - val_accuracy: 0.8104 - val_loss: 0.3037\n",
      "Epoch 20/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.3488 - val_accuracy: 0.8096 - val_loss: 0.2971\n",
      "Epoch 21/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.3359 - val_accuracy: 0.8177 - val_loss: 0.2935\n",
      "Epoch 22/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.3252 - val_accuracy: 0.8177 - val_loss: 0.2870\n",
      "Epoch 23/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.3271 - val_accuracy: 0.8297 - val_loss: 0.2880\n",
      "Epoch 24/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.3230 - val_accuracy: 0.8353 - val_loss: 0.2801\n",
      "Epoch 25/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3117 - val_accuracy: 0.8249 - val_loss: 0.2768\n",
      "Epoch 26/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.3125 - val_accuracy: 0.8072 - val_loss: 0.2928\n",
      "Epoch 27/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.3125 - val_accuracy: 0.8321 - val_loss: 0.2701\n",
      "Epoch 28/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.2977 - val_accuracy: 0.8064 - val_loss: 0.2806\n",
      "Epoch 29/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.2975 - val_accuracy: 0.8129 - val_loss: 0.2673\n",
      "Epoch 30/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.2996 - val_accuracy: 0.8249 - val_loss: 0.2756\n",
      "Epoch 31/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.2991 - val_accuracy: 0.8104 - val_loss: 0.2705\n",
      "Epoch 32/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.2906 - val_accuracy: 0.8217 - val_loss: 0.2723\n",
      "Epoch 33/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.2927 - val_accuracy: 0.8297 - val_loss: 0.2703\n",
      "Epoch 34/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.2898 - val_accuracy: 0.8249 - val_loss: 0.2560\n",
      "Epoch 35/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.2834 - val_accuracy: 0.8161 - val_loss: 0.2720\n",
      "Epoch 36/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.2829 - val_accuracy: 0.8145 - val_loss: 0.2750\n",
      "Epoch 37/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.2869 - val_accuracy: 0.8345 - val_loss: 0.2578\n",
      "Epoch 38/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.2808 - val_accuracy: 0.8369 - val_loss: 0.2511\n",
      "Epoch 39/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.2734 - val_accuracy: 0.8273 - val_loss: 0.2642\n",
      "Epoch 40/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.2799 - val_accuracy: 0.8321 - val_loss: 0.2527\n",
      "Epoch 41/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.2756 - val_accuracy: 0.8249 - val_loss: 0.2616\n",
      "Epoch 42/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.2713 - val_accuracy: 0.8321 - val_loss: 0.2577\n",
      "Epoch 43/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.2727 - val_accuracy: 0.8145 - val_loss: 0.2589\n",
      "Epoch 44/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.2692 - val_accuracy: 0.8305 - val_loss: 0.2549\n",
      "Epoch 45/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.2680 - val_accuracy: 0.8185 - val_loss: 0.2661\n",
      "Epoch 46/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.2698 - val_accuracy: 0.8161 - val_loss: 0.2571\n",
      "Epoch 47/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.2699 - val_accuracy: 0.8289 - val_loss: 0.2488\n",
      "Epoch 48/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.2714 - val_accuracy: 0.8225 - val_loss: 0.2559\n",
      "Epoch 49/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.2649 - val_accuracy: 0.8265 - val_loss: 0.2458\n",
      "Epoch 50/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.2716 - val_accuracy: 0.8241 - val_loss: 0.2489\n",
      "Epoch 51/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.2641 - val_accuracy: 0.8241 - val_loss: 0.2448\n",
      "Epoch 52/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.2636 - val_accuracy: 0.8265 - val_loss: 0.2456\n",
      "Epoch 53/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.2638 - val_accuracy: 0.8145 - val_loss: 0.2731\n",
      "Epoch 54/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.2657 - val_accuracy: 0.8257 - val_loss: 0.2421\n",
      "Epoch 55/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.2635 - val_accuracy: 0.8241 - val_loss: 0.2435\n",
      "Epoch 56/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.2513 - val_accuracy: 0.8313 - val_loss: 0.2389\n",
      "Epoch 57/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.2548 - val_accuracy: 0.8241 - val_loss: 0.2583\n",
      "Epoch 58/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.2610 - val_accuracy: 0.8321 - val_loss: 0.2465\n",
      "Epoch 59/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.2572 - val_accuracy: 0.8273 - val_loss: 0.2578\n",
      "Epoch 60/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.2528 - val_accuracy: 0.8361 - val_loss: 0.2391\n",
      "Epoch 61/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.2553 - val_accuracy: 0.8345 - val_loss: 0.2458\n",
      "Epoch 62/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.2651 - val_accuracy: 0.8209 - val_loss: 0.2523\n",
      "Epoch 63/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.2711 - val_accuracy: 0.8305 - val_loss: 0.2446\n",
      "Epoch 64/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.2609 - val_accuracy: 0.8249 - val_loss: 0.2400\n",
      "Epoch 65/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8204 - loss: 0.2672 - val_accuracy: 0.8169 - val_loss: 0.2489\n",
      "Epoch 66/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.2659 - val_accuracy: 0.8321 - val_loss: 0.2465\n",
      "Test Accuracy: 83.13%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # track validation loss\n",
    "    patience=10,              # stop if no improvement for 10 epochs\n",
    "    restore_best_weights=True # roll back to best model\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train_categorical,\n",
    "    validation_data=(X_test, y_test_categorical),\n",
    "    epochs=100,               # max epochs\n",
    "    batch_size=32,            # you can tune (16, 32, 64…)\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "221258de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def predict_crops_full_dataset(\n",
    "    model,              # Trained neural network\n",
    "    le,                 # LabelEncoder used for crops\n",
    "    ct,                 # ColumnTransformer used for preprocessing\n",
    "    data,               # Original dataset (with ETc, Kc, etc.)\n",
    "    selected_crop=None  # Optional: crop selected by farmer\n",
    "):\n",
    "    \"\"\"\n",
    "    Predicts crops for the entire dataset and optionally provides info for a selected crop.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained neural network\n",
    "    - le: LabelEncoder for crops\n",
    "    - ct: ColumnTransformer used for preprocessing\n",
    "    - data: original dataset (with ETc, Kc, etc.)\n",
    "    - selected_crop: crop name selected by farmer (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - dict containing:\n",
    "        - 'selected_crop_info': ETc, Kc, growth stage, season (if selected_crop provided)\n",
    "        - 'data_with_predictions': original dataset + 'Predicted_Crop' column\n",
    "    \"\"\"\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # --- Part 1: Farmer-selected crop info ---\n",
    "    if selected_crop:\n",
    "        crop_info = data[data[\"crop name\"] == selected_crop][\n",
    "            [\"ETc\", \"Kc\", \"growth stage\", \"Season\"]\n",
    "        ]\n",
    "        result['selected_crop_info'] = crop_info.reset_index(drop=True)\n",
    "    else:\n",
    "        result['selected_crop_info'] = None\n",
    "    \n",
    "    # --- Part 2: Predict crop for entire dataset ---\n",
    "    # Remove target and unnecessary columns\n",
    "    X_all = data.drop([\"crop name\", \"Date\", \"Radiation_Sanity\"], axis=1, errors='ignore')\n",
    "    \n",
    "    # Ensure Month column exists\n",
    "    if \"Month\" not in X_all.columns and \"Date\" in data.columns:\n",
    "        X_all[\"Month\"] = pd.to_datetime(data[\"Date\"], errors=\"coerce\").dt.month\n",
    "    \n",
    "    # Preprocess features\n",
    "    X_all_processed = ct.transform(X_all)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_prob = model.predict(X_all_processed)\n",
    "    y_pred_classes = y_pred_prob.argmax(axis=1)\n",
    "    y_pred_crop_names = le.inverse_transform(y_pred_classes)\n",
    "    \n",
    "    # Add predictions to dataset\n",
    "    data_with_predictions = data.copy()\n",
    "    data_with_predictions[\"Predicted_Crop\"] = y_pred_crop_names\n",
    "    \n",
    "    result['data_with_predictions'] = data_with_predictions\n",
    "    \n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
